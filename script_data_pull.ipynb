{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "9218ccc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from collections import defaultdict, Counter\n",
    "from collections import OrderedDict\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "21cffdfb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jeremy.yap\\OneDrive - Meinhardt Singapore Pte Ltd\\Python\\lighthouse_dash\n",
      "c:\\Users\\jeremy.yap\\OneDrive - Meinhardt Singapore Pte Ltd\\Python\\lighthouse_dash\n",
      "Found workbooks:\n",
      "• assessment_guide_diriyah.xlsm\n",
      "• assessment_guide_qiddiya.xlsm\n",
      "Reference file sheets: ['P&M Schedule', 'P&M RIsk', 'Cost Estimation & Optimization', 'D&C - Quality', 'D&C - Procurement', 'D&C - HSE & Welfare', 'Innovation & Technology', 'D&C - Construction', 'Design & Technical', 'Strategy & Operations', 'Glossary', 'Visuals Menu']\n"
     ]
    }
   ],
   "source": [
    "warnings.simplefilter(\"ignore\", UserWarning)\n",
    "\n",
    "repo_root = Path().cwd()\n",
    "print(repo_root)\n",
    "print(repo_root)\n",
    "\n",
    "ref_path  = repo_root / \"master_sheet_reference_v2.xlsx\"\n",
    "ag_folder    = repo_root / \"assessment_guide\"\n",
    "ag_files  = sorted(ag_folder.glob(\"*.xls*\"))\n",
    "\n",
    "print(\"Found workbooks:\")\n",
    "for p in ag_files:\n",
    "    print(\"•\", p.name)\n",
    "\n",
    "ref_sheets  = pd.read_excel(ref_path,  sheet_name=None)\n",
    "print(\"Reference file sheets:\", list(ref_sheets.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "777b2a6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping sheet 'Visuals Menu': missing \"Table\" and \"Columm\" columns\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'P&M Schedule': {'AddDataPoint(P&M)': ['Additional Data Point',\n",
       "    'Value',\n",
       "    'Year',\n",
       "    'Value Completed (Baseline) in M SAR',\n",
       "    'Value Completed (Actual) in M SAR',\n",
       "    'Value Completed (Forecast) in M SAR'],\n",
       "   'DevCoAssessmentAnalysis(P&M)': ['Assessment Criteria', 'Value']}},\n",
       " {'P&M RIsk': {'AddDataPoint(P&M)': ['Additional Data Point',\n",
       "    'Value',\n",
       "    'Risk Category',\n",
       "    'Number of Risk Items',\n",
       "    'Risk',\n",
       "    'Source',\n",
       "    'Potential Impact',\n",
       "    'Risk Rating',\n",
       "    'Risk Status',\n",
       "    'Current Measures'],\n",
       "   'DevCoAssessmentAnalysis(P&M)': ['Assessment Criteria',\n",
       "    'Value',\n",
       "    'Rating']}},\n",
       " {'Cost Estimation & Optimization': {'AddDataPoint(CE&O)': ['Additional Data Point',\n",
       "    'Value',\n",
       "    'Year',\n",
       "    'Budget Value (Baseline) in M SAR',\n",
       "    'Budget Value (Revised) in M SAR',\n",
       "    'Budget Value (Forecast) in M SAR'],\n",
       "   'DevCoAssessmentAnalysis(CE&O)': ['Assessment Criteria', 'Value', 'Rating'],\n",
       "   'DevCoAssessmentInput(CE&O)': ['Data Point', 'Input Value']}},\n",
       " {'D&C - Quality': {'AddDataPoint(D&C)': ['Number of Quality Audits',\n",
       "    'Month',\n",
       "    'Additional Data Point',\n",
       "    'Value'],\n",
       "   'DevCoAssessmentAnalysis(D&C)': ['Assessment Criteria', 'Value'],\n",
       "   'DevCoAssessmentInput(D&C)': ['Assessment Criteria',\n",
       "    'Data Point',\n",
       "    'Input Value']}},\n",
       " {'D&C - Procurement': {'AddDataPoint(D&C)': ['Additional Data Point',\n",
       "    'Value',\n",
       "    'Parameter',\n",
       "    'Baseline',\n",
       "    'Actual',\n",
       "    'Forecast'],\n",
       "   'DevCoAssessmentAnalysis(D&C)': ['Assessment Criteria',\n",
       "    'Value',\n",
       "    'Performance Signal',\n",
       "    'Performance Signal Score'],\n",
       "   'DevCoAssessmentInput(D&C)': ['Assessment Criteria',\n",
       "    'Data Point',\n",
       "    'Input Value']}},\n",
       " {'D&C - HSE & Welfare': {'AddDataPoint(D&C)': ['Additional Data Point',\n",
       "    'Value',\n",
       "    'Incident Category',\n",
       "    'Number of Incidents (To-Date)',\n",
       "    'Number of Investigations in Progress',\n",
       "    'Number of Investigations Completed',\n",
       "    'Number of Investigations Pending Approval',\n",
       "    'Audits/Inspections',\n",
       "    'In Progress_audits',\n",
       "    'Completed_audits',\n",
       "    'Remaining Planned',\n",
       "    'Actions',\n",
       "    'In Progress_actions',\n",
       "    'Completed_actions',\n",
       "    'Pending Approval',\n",
       "    'Year',\n",
       "    'Value_training']}},\n",
       " {'Innovation & Technology': {'AddDataPoint(I&T)': ['Additional Data Point',\n",
       "    'Value'],\n",
       "   'DevCoAssessmentAnalysis(I&T)': ['Assessment Criteria',\n",
       "    'Value',\n",
       "    'Rating',\n",
       "    'Performance Signal Score',\n",
       "    'Performance Signal']}},\n",
       " {'D&C - Construction': {'AddDataPoint(D&C)': ['Program',\n",
       "    'Acquired (Ha)',\n",
       "    'Under Negotiation (Ha)',\n",
       "    'Pending (Ha)',\n",
       "    'Additional Data Point',\n",
       "    'Value'],\n",
       "   'DevCoAssessmentAnalysis(D&C)': ['Performance Signal Score',\n",
       "    'Assessment Criteria',\n",
       "    'Value',\n",
       "    'Rating'],\n",
       "   'DevCoAssessmentInput(D&C)': ['Input Value']}},\n",
       " {'Design & Technical': {'DevCoAssessmentAnalysis(D&T)': ['Remarks 3',\n",
       "    'Performance Signal',\n",
       "    'Performance Signal Score',\n",
       "    'Value',\n",
       "    'Rating',\n",
       "    'Assessment Criteria',\n",
       "    'Key Topic',\n",
       "    'Key Topic Score'],\n",
       "   'DevCoAssessmentInput(D&T)': ['Input Value', 'Data Point']}},\n",
       " {'Strategy & Operations': {'AddDataPoint(S&O)': ['Weightage',\n",
       "    'Name of the KPI'],\n",
       "   'DevCoAssessmentAnalysis(S&O)': ['Rating',\n",
       "    'Assessment Criteria',\n",
       "    'Value']}},\n",
       " {'Glossary': {'Glossary': ['Section', 'Term', 'Description']}}]"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Unpack reference file\n",
    "ref_tabs = []     \n",
    "\n",
    "for sheet_name, df in ref_sheets.items():\n",
    "    if {\"Table\", \"Column\"}.issubset(df.columns): # Check if columns titled \"Table\" and \"Column\" exist\n",
    "        table_cols = (\n",
    "            df.groupby(\"Table\")[\"Column\"]\n",
    "              .apply(list)\n",
    "              .to_dict()\n",
    "        )\n",
    "        ref_tabs.append({ sheet_name: table_cols })\n",
    "    else:\n",
    "        print(f\"Skipping sheet {sheet_name!r}: missing \\\"Table\\\" and \\\"Columm\\\" columns\")\n",
    "\n",
    "ref_tabs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "ae9d7194",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ Table “AddDataPoint(P&M)” has duplicate columns: ['Additional Data Point', 'Value']\n",
      "⚠️ Table “DevCoAssessmentAnalysis(P&M)” has duplicate columns: ['Assessment Criteria', 'Value']\n",
      "✅ Table “AddDataPoint(CE&O)” has no repeated columns.\n",
      "✅ Table “DevCoAssessmentAnalysis(CE&O)” has no repeated columns.\n",
      "✅ Table “DevCoAssessmentInput(CE&O)” has no repeated columns.\n",
      "⚠️ Table “AddDataPoint(D&C)” has duplicate columns: ['Additional Data Point', 'Value']\n",
      "⚠️ Table “DevCoAssessmentAnalysis(D&C)” has duplicate columns: ['Assessment Criteria', 'Value', 'Performance Signal Score']\n",
      "⚠️ Table “DevCoAssessmentInput(D&C)” has duplicate columns: ['Assessment Criteria', 'Data Point', 'Input Value']\n",
      "✅ Table “AddDataPoint(I&T)” has no repeated columns.\n",
      "✅ Table “DevCoAssessmentAnalysis(I&T)” has no repeated columns.\n",
      "✅ Table “DevCoAssessmentAnalysis(D&T)” has no repeated columns.\n",
      "✅ Table “DevCoAssessmentInput(D&T)” has no repeated columns.\n",
      "✅ Table “AddDataPoint(S&O)” has no repeated columns.\n",
      "✅ Table “DevCoAssessmentAnalysis(S&O)” has no repeated columns.\n",
      "✅ Table “Glossary” has no repeated columns.\n",
      "defaultdict(<class 'list'>, {'AddDataPoint(P&M)': ['Additional Data Point', 'Value', 'Year', 'Value Completed (Baseline) in M SAR', 'Value Completed (Actual) in M SAR', 'Value Completed (Forecast) in M SAR', 'Risk Category', 'Number of Risk Items', 'Risk', 'Source', 'Potential Impact', 'Risk Rating', 'Risk Status', 'Current Measures'], 'DevCoAssessmentAnalysis(P&M)': ['Assessment Criteria', 'Value', 'Rating'], 'AddDataPoint(CE&O)': ['Additional Data Point', 'Value', 'Year', 'Budget Value (Baseline) in M SAR', 'Budget Value (Revised) in M SAR', 'Budget Value (Forecast) in M SAR'], 'DevCoAssessmentAnalysis(CE&O)': ['Assessment Criteria', 'Value', 'Rating'], 'DevCoAssessmentInput(CE&O)': ['Data Point', 'Input Value'], 'AddDataPoint(D&C)': ['Number of Quality Audits', 'Month', 'Additional Data Point', 'Value', 'Parameter', 'Baseline', 'Actual', 'Forecast', 'Incident Category', 'Number of Incidents (To-Date)', 'Number of Investigations in Progress', 'Number of Investigations Completed', 'Number of Investigations Pending Approval', 'Audits/Inspections', 'In Progress_audits', 'Completed_audits', 'Remaining Planned', 'Actions', 'In Progress_actions', 'Completed_actions', 'Pending Approval', 'Year', 'Value_training', 'Program', 'Acquired (Ha)', 'Under Negotiation (Ha)', 'Pending (Ha)'], 'DevCoAssessmentAnalysis(D&C)': ['Assessment Criteria', 'Value', 'Performance Signal', 'Performance Signal Score', 'Rating'], 'DevCoAssessmentInput(D&C)': ['Assessment Criteria', 'Data Point', 'Input Value'], 'AddDataPoint(I&T)': ['Additional Data Point', 'Value'], 'DevCoAssessmentAnalysis(I&T)': ['Assessment Criteria', 'Value', 'Rating', 'Performance Signal Score', 'Performance Signal'], 'DevCoAssessmentAnalysis(D&T)': ['Remarks 3', 'Performance Signal', 'Performance Signal Score', 'Value', 'Rating', 'Assessment Criteria', 'Key Topic', 'Key Topic Score'], 'DevCoAssessmentInput(D&T)': ['Input Value', 'Data Point'], 'AddDataPoint(S&O)': ['Weightage', 'Name of the KPI'], 'DevCoAssessmentAnalysis(S&O)': ['Rating', 'Assessment Criteria', 'Value'], 'Glossary': ['Section', 'Term', 'Description']})\n"
     ]
    }
   ],
   "source": [
    "table_cols = defaultdict(list)\n",
    "\n",
    "for tab_dict in ref_tabs:\n",
    "    sheet_map = next(iter(tab_dict.values()))\n",
    "    for table_name, cols in sheet_map.items():\n",
    "        table_cols[table_name].extend(cols)\n",
    "        \n",
    "for table_name, all_cols in table_cols.items():\n",
    "    counts = Counter(all_cols)\n",
    "    dupes = [col for col, n in counts.items() if n > 1]\n",
    "    if dupes:\n",
    "        print(f\"⚠️ Table “{table_name}” has duplicate columns: {dupes}\")\n",
    "    else:\n",
    "        print(f\"✅ Table “{table_name}” has no repeated columns.\")\n",
    "\n",
    "for table_name, cols in table_cols.items():\n",
    "    table_cols[table_name] = list(OrderedDict.fromkeys(cols))\n",
    "\n",
    "print(table_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "7199cd16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# all_cols = []\n",
    "# for cols in table_cols.values():\n",
    "#     all_cols.extend(cols)\n",
    "# dupe_cols = {c for c, cnt in Counter(all_cols).items() if cnt > 1}\n",
    "\n",
    "# dupe_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "015e3f38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading 'assessment_guide_diriyah.xlsm' (suffix = diriyah)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Worksheet named 'Glossary' not found",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[94]\u001b[39m\u001b[32m, line 13\u001b[39m\n\u001b[32m     11\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m table_name, cols \u001b[38;5;129;01min\u001b[39;00m table_cols.items():\n\u001b[32m     12\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m table_name == \u001b[33m'\u001b[39m\u001b[33mGlossary\u001b[39m\u001b[33m'\u001b[39m:\n\u001b[32m---> \u001b[39m\u001b[32m13\u001b[39m         glossary_df = \u001b[43mpd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread_excel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msheet_name\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtable_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheader\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m4\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     14\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     15\u001b[39m         df = pd.read_excel(data_path, sheet_name=table_name, header=\u001b[32m4\u001b[39m)  \u001b[38;5;66;03m# pull in AG data. Each table name from column reference sheet is a sheet name in the AG file.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\jeremy.yap\\OneDrive - Meinhardt Singapore Pte Ltd\\Python\\.venv\\Lib\\site-packages\\pandas\\io\\excel\\_base.py:508\u001b[39m, in \u001b[36mread_excel\u001b[39m\u001b[34m(io, sheet_name, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skiprows, nrows, na_values, keep_default_na, na_filter, verbose, parse_dates, date_parser, date_format, thousands, decimal, comment, skipfooter, storage_options, dtype_backend, engine_kwargs)\u001b[39m\n\u001b[32m    502\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    503\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mEngine should not be specified when passing \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    504\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33man ExcelFile - ExcelFile already has the engine set\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    505\u001b[39m     )\n\u001b[32m    507\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m508\u001b[39m     data = \u001b[43mio\u001b[49m\u001b[43m.\u001b[49m\u001b[43mparse\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    509\u001b[39m \u001b[43m        \u001b[49m\u001b[43msheet_name\u001b[49m\u001b[43m=\u001b[49m\u001b[43msheet_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    510\u001b[39m \u001b[43m        \u001b[49m\u001b[43mheader\u001b[49m\u001b[43m=\u001b[49m\u001b[43mheader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    511\u001b[39m \u001b[43m        \u001b[49m\u001b[43mnames\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnames\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    512\u001b[39m \u001b[43m        \u001b[49m\u001b[43mindex_col\u001b[49m\u001b[43m=\u001b[49m\u001b[43mindex_col\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    513\u001b[39m \u001b[43m        \u001b[49m\u001b[43musecols\u001b[49m\u001b[43m=\u001b[49m\u001b[43musecols\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    514\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    515\u001b[39m \u001b[43m        \u001b[49m\u001b[43mconverters\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconverters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    516\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtrue_values\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtrue_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    517\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfalse_values\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfalse_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    518\u001b[39m \u001b[43m        \u001b[49m\u001b[43mskiprows\u001b[49m\u001b[43m=\u001b[49m\u001b[43mskiprows\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    519\u001b[39m \u001b[43m        \u001b[49m\u001b[43mnrows\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnrows\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    520\u001b[39m \u001b[43m        \u001b[49m\u001b[43mna_values\u001b[49m\u001b[43m=\u001b[49m\u001b[43mna_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    521\u001b[39m \u001b[43m        \u001b[49m\u001b[43mkeep_default_na\u001b[49m\u001b[43m=\u001b[49m\u001b[43mkeep_default_na\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    522\u001b[39m \u001b[43m        \u001b[49m\u001b[43mna_filter\u001b[49m\u001b[43m=\u001b[49m\u001b[43mna_filter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    523\u001b[39m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m=\u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    524\u001b[39m \u001b[43m        \u001b[49m\u001b[43mparse_dates\u001b[49m\u001b[43m=\u001b[49m\u001b[43mparse_dates\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    525\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdate_parser\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdate_parser\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    526\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdate_format\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdate_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    527\u001b[39m \u001b[43m        \u001b[49m\u001b[43mthousands\u001b[49m\u001b[43m=\u001b[49m\u001b[43mthousands\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    528\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdecimal\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdecimal\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    529\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcomment\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcomment\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    530\u001b[39m \u001b[43m        \u001b[49m\u001b[43mskipfooter\u001b[49m\u001b[43m=\u001b[49m\u001b[43mskipfooter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    531\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdtype_backend\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdtype_backend\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    532\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    533\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    534\u001b[39m     \u001b[38;5;66;03m# make sure to close opened file handles\u001b[39;00m\n\u001b[32m    535\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m should_close:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\jeremy.yap\\OneDrive - Meinhardt Singapore Pte Ltd\\Python\\.venv\\Lib\\site-packages\\pandas\\io\\excel\\_base.py:1616\u001b[39m, in \u001b[36mExcelFile.parse\u001b[39m\u001b[34m(self, sheet_name, header, names, index_col, usecols, converters, true_values, false_values, skiprows, nrows, na_values, parse_dates, date_parser, date_format, thousands, comment, skipfooter, dtype_backend, **kwds)\u001b[39m\n\u001b[32m   1576\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mparse\u001b[39m(\n\u001b[32m   1577\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   1578\u001b[39m     sheet_name: \u001b[38;5;28mstr\u001b[39m | \u001b[38;5;28mint\u001b[39m | \u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mint\u001b[39m] | \u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mstr\u001b[39m] | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[32m0\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1596\u001b[39m     **kwds,\n\u001b[32m   1597\u001b[39m ) -> DataFrame | \u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, DataFrame] | \u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mint\u001b[39m, DataFrame]:\n\u001b[32m   1598\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   1599\u001b[39m \u001b[33;03m    Parse specified sheet(s) into a DataFrame.\u001b[39;00m\n\u001b[32m   1600\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m   1614\u001b[39m \u001b[33;03m    >>> file.parse()  # doctest: +SKIP\u001b[39;00m\n\u001b[32m   1615\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1616\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_reader\u001b[49m\u001b[43m.\u001b[49m\u001b[43mparse\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1617\u001b[39m \u001b[43m        \u001b[49m\u001b[43msheet_name\u001b[49m\u001b[43m=\u001b[49m\u001b[43msheet_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1618\u001b[39m \u001b[43m        \u001b[49m\u001b[43mheader\u001b[49m\u001b[43m=\u001b[49m\u001b[43mheader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1619\u001b[39m \u001b[43m        \u001b[49m\u001b[43mnames\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnames\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1620\u001b[39m \u001b[43m        \u001b[49m\u001b[43mindex_col\u001b[49m\u001b[43m=\u001b[49m\u001b[43mindex_col\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1621\u001b[39m \u001b[43m        \u001b[49m\u001b[43musecols\u001b[49m\u001b[43m=\u001b[49m\u001b[43musecols\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1622\u001b[39m \u001b[43m        \u001b[49m\u001b[43mconverters\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconverters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1623\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtrue_values\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtrue_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1624\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfalse_values\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfalse_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1625\u001b[39m \u001b[43m        \u001b[49m\u001b[43mskiprows\u001b[49m\u001b[43m=\u001b[49m\u001b[43mskiprows\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1626\u001b[39m \u001b[43m        \u001b[49m\u001b[43mnrows\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnrows\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1627\u001b[39m \u001b[43m        \u001b[49m\u001b[43mna_values\u001b[49m\u001b[43m=\u001b[49m\u001b[43mna_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1628\u001b[39m \u001b[43m        \u001b[49m\u001b[43mparse_dates\u001b[49m\u001b[43m=\u001b[49m\u001b[43mparse_dates\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1629\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdate_parser\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdate_parser\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1630\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdate_format\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdate_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1631\u001b[39m \u001b[43m        \u001b[49m\u001b[43mthousands\u001b[49m\u001b[43m=\u001b[49m\u001b[43mthousands\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1632\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcomment\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcomment\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1633\u001b[39m \u001b[43m        \u001b[49m\u001b[43mskipfooter\u001b[49m\u001b[43m=\u001b[49m\u001b[43mskipfooter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1634\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdtype_backend\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdtype_backend\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1635\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1636\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\jeremy.yap\\OneDrive - Meinhardt Singapore Pte Ltd\\Python\\.venv\\Lib\\site-packages\\pandas\\io\\excel\\_base.py:773\u001b[39m, in \u001b[36mBaseExcelReader.parse\u001b[39m\u001b[34m(self, sheet_name, header, names, index_col, usecols, dtype, true_values, false_values, skiprows, nrows, na_values, verbose, parse_dates, date_parser, date_format, thousands, decimal, comment, skipfooter, dtype_backend, **kwds)\u001b[39m\n\u001b[32m    770\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mReading sheet \u001b[39m\u001b[38;5;132;01m{\u001b[39;00masheetname\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m    772\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(asheetname, \u001b[38;5;28mstr\u001b[39m):\n\u001b[32m--> \u001b[39m\u001b[32m773\u001b[39m     sheet = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mget_sheet_by_name\u001b[49m\u001b[43m(\u001b[49m\u001b[43masheetname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    774\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:  \u001b[38;5;66;03m# assume an integer if not a string\u001b[39;00m\n\u001b[32m    775\u001b[39m     sheet = \u001b[38;5;28mself\u001b[39m.get_sheet_by_index(asheetname)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\jeremy.yap\\OneDrive - Meinhardt Singapore Pte Ltd\\Python\\.venv\\Lib\\site-packages\\pandas\\io\\excel\\_openpyxl.py:582\u001b[39m, in \u001b[36mOpenpyxlReader.get_sheet_by_name\u001b[39m\u001b[34m(self, name)\u001b[39m\n\u001b[32m    581\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mget_sheet_by_name\u001b[39m(\u001b[38;5;28mself\u001b[39m, name: \u001b[38;5;28mstr\u001b[39m):\n\u001b[32m--> \u001b[39m\u001b[32m582\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mraise_if_bad_sheet_by_name\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    583\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.book[name]\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\jeremy.yap\\OneDrive - Meinhardt Singapore Pte Ltd\\Python\\.venv\\Lib\\site-packages\\pandas\\io\\excel\\_base.py:624\u001b[39m, in \u001b[36mBaseExcelReader.raise_if_bad_sheet_by_name\u001b[39m\u001b[34m(self, name)\u001b[39m\n\u001b[32m    622\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mraise_if_bad_sheet_by_name\u001b[39m(\u001b[38;5;28mself\u001b[39m, name: \u001b[38;5;28mstr\u001b[39m) -> \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    623\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.sheet_names:\n\u001b[32m--> \u001b[39m\u001b[32m624\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mWorksheet named \u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m not found\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mValueError\u001b[39m: Worksheet named 'Glossary' not found"
     ]
    }
   ],
   "source": [
    "file_frames = []   # to collect df for each file\n",
    "\n",
    "for data_path in ag_files:\n",
    "    # derive suffix\n",
    "    parts = data_path.stem.split(\"assessment_guide_\")\n",
    "    suffix = parts[1]\n",
    "\n",
    "    print(f\"Reading {data_path.name!r} (suffix = {suffix})\")\n",
    "\n",
    "    pieces = []\n",
    "    for table_name, cols in table_cols.items():\n",
    "        if table_name == 'Glossary&Definitions':\n",
    "            glossary_df = pd.read_excel(data_path, sheet_name=table_name, header=4)\n",
    "        else:\n",
    "            df = pd.read_excel(data_path, sheet_name=table_name, header=4)  # pull in AG data. Each table name from column reference sheet is a sheet name in the AG file.\n",
    "            df.columns = (\n",
    "                df.columns\n",
    "                .str.replace(r'\\s*\\n\\s*', ' ', regex=True)  \n",
    "                .str.strip()                                \n",
    "            )\n",
    "\n",
    "            # print(df.columns)\n",
    "\n",
    "            present = [c for c in cols if c in df.columns] # cols = columns from reference, present = columns in AG\n",
    "            missing = set(cols) - set(present)\n",
    "            if missing:\n",
    "                print(f\"⚠️ In table {table_name!r}, missing columns: {missing}\")\n",
    "\n",
    "            df_sub = df[present].copy()\n",
    "            for c in missing:\n",
    "                df_sub[c] = pd.NA\n",
    "\n",
    "            # rename_map = {\n",
    "            #     col: f\"{col}_{table_name}\"\n",
    "            #     for col in df_sub.columns\n",
    "            #     if col in dupe_cols\n",
    "            # }\n",
    "            # if rename_map:\n",
    "            #     df_sub = df_sub.rename(columns=rename_map)\n",
    "\n",
    "            pieces.append(df_sub)\n",
    "\n",
    "    file_df = pd.concat(pieces, axis=1) # master df for each file\n",
    "\n",
    "    file_df.insert(0, \"DevCo\", [suffix] * len(file_df)) # append DevCo column\n",
    "\n",
    "    file_frames.append(file_df) # append master df for each file to a list\n",
    "\n",
    "master_df = pd.concat(file_frames, axis=0, ignore_index=True) # stack master df for each file row-wise\n",
    "\n",
    "print(\"Final master shape:\", master_df.shape)\n",
    "print(\"Glossary shape:\", glossary_df.shape)\n",
    "# master_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "1b2fcea7",
   "metadata": {},
   "outputs": [],
   "source": [
    "for df in file_frames:\n",
    "    dups = df.columns[df.columns.duplicated()].unique()\n",
    "    if len(dups):\n",
    "        print(\"⚠️ Duplicated column names in this frame:\", dups.tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59ad4589",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "b53ee174",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Saved master sheet to WindowsPath('c:/Users/jeremy.yap/OneDrive - Meinhardt Singapore Pte Ltd/Python/lighthouse_dash/master_sheet.xlsx')\n"
     ]
    }
   ],
   "source": [
    "output_path = repo_root/ 'master_sheet.xlsx'\n",
    "master_df.to_excel(output_path, index=False)\n",
    "\n",
    "print(f\"✅ Saved master sheet to {output_path!r}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7c7e919",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
